{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18605ae4",
   "metadata": {},
   "source": [
    "Load needed models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "accccb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3383fc",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce3591c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.DataFrame()\n",
    "training = pd.read_excel(\"NCAA_Seed_Training_Set2.0.xlsx\", sheet_name=\"NCAA_Seed_Training_Set2.0\")\n",
    "training_sheets = pd.read_excel(\"NCAA_Seed_Training_Set2.0.xlsx\", sheet_name=None)\n",
    "testing = pd.DataFrame()\n",
    "testing = pd.read_excel(\"NCAA_Seed_Test_Set2.0.xlsx\", sheet_name=\"NCAA_Seed_Test_Set2.0\")\n",
    "testing_sheets = pd.read_excel(\"NCAA_Seed_Training_Set2.0.xlsx\", sheet_name=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927cfecb",
   "metadata": {},
   "source": [
    "Add outside data NET conference ranking to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9316c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_rank(row, sheets):\n",
    "    season = row[\"Season\"]\n",
    "    conf = row[\"Conference\"]\n",
    "    \n",
    "    # Convert season to string in case it's numeric\n",
    "    season = str(season)\n",
    "    \n",
    "    # Get the appropriate sheet\n",
    "    if season in sheets:\n",
    "        season_df = sheets[season]\n",
    "        \n",
    "        match = season_df.loc[\n",
    "            season_df[\"Conference\"] == conf,\n",
    "            \"Rank\"\n",
    "        ]\n",
    "        \n",
    "        if not match.empty:\n",
    "            return match.iloc[0]\n",
    "    \n",
    "    return None  # if no match found\n",
    "\n",
    "training[\"Conf Rank\"] = np.nan\n",
    "training[\"Conf Rank\"] = training.apply(get_conf_rank, axis=1, args=(training_sheets,))\n",
    "\n",
    "testing[\"Conf Rank\"] = np.nan\n",
    "testing[\"Conf Rank\"] = training.apply(get_conf_rank, axis=1, args=(training_sheets,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a3b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_vars1 = [\"Q1 Win\", \"Q1 Loss\", \"Q2 Win\", \"Q2 Loss\", \"Q3 Win\", \"Q3 Loss\", \"Q4 Win\", \"Q4 Loss\", \"NET Rank\", \"Conf Rank\"]\n",
    "\n",
    "training_filt = training.dropna(subset = [\"NET Rank\"])\n",
    "testing_filt = testing.dropna(subset = [\"NET Rank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4cdc032",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_train = training_filt.dropna(subset=[\"Bid Type\"])\n",
    "X_reg1 = seed_train[ind_vars1]\n",
    "y_reg = seed_train[\"Overall Seed\"]\n",
    "\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(\n",
    "    X_reg1, y_reg, random_state=0, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4d8589b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R²: 0.935\n",
      "Cross-validated R² scores: [0.86229868 0.95594984 0.88826479 0.94293319 0.9332869 ]\n",
      "Mean CV R²: 0.917\n",
      "Std Dev: 0.035\n",
      "\n",
      "Feature Importances:\n",
      "NET Rank     0.757055\n",
      "Q1 Win       0.118567\n",
      "NETSOS       0.039140\n",
      "Conf Rank    0.038234\n",
      "Q1 Loss      0.013096\n",
      "Q2 Win       0.010841\n",
      "Q2 Loss      0.009822\n",
      "Q3 Win       0.004513\n",
      "Q4 Win       0.004410\n",
      "Q4 Loss      0.003387\n",
      "Q3 Loss      0.000934\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Model\n",
    "gbr = GradientBoostingRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "gbr.fit(XTrain, yTrain)\n",
    "\n",
    "# Evaluate\n",
    "yPred = gbr.predict(XTest)\n",
    "print('Test R²:', round(metrics.r2_score(yTest, yPred), 3))\n",
    "\n",
    "# Cross-validation\n",
    "scores = cross_val_score(gbr, X_reg1, y_reg, cv=5, scoring='r2')\n",
    "\n",
    "print(\"Cross-validated R² scores:\", scores)\n",
    "print(\"Mean CV R²:\", round(scores.mean(), 3))\n",
    "print(\"Std Dev:\", round(scores.std(), 3))\n",
    "\n",
    "importance = pd.Series(\n",
    "    gbr.feature_importances_,\n",
    "    index=ind_vars1\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc80b90",
   "metadata": {},
   "source": [
    "Generate predictions for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53dfb88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = testing.copy()\n",
    "final_pred[\"Initial Seed\"] = np.nan\n",
    "\n",
    "filtered_pred = testing_filt[\n",
    "    (testing_filt[\"Bid Type\"] == \"AL\") |\n",
    "    (testing_filt[\"Bid Type\"] == \"AQ\")\n",
    "]\n",
    "\n",
    "X_reg1_test = filtered_pred[ind_vars1]\n",
    "\n",
    "predictions = gbr.predict(X_reg1_test)\n",
    "\n",
    "final_pred.loc[filtered_pred.index, \"Initial Seed\"] = predictions\n",
    "final_pred[\"Overall Seed\"] = final_pred[\"Initial Seed\"].round(0)\n",
    "final_pred[\"Overall Seed\"] = final_pred[\"Overall Seed\"].clip(lower=1, upper=68)\n",
    "final_pred[\"Overall Seed\"] = final_pred[\"Overall Seed\"].fillna(0).astype(int)\n",
    "\n",
    "final_pred = final_pred[[\"RecordID\", \"Overall Seed\"]]\n",
    "\n",
    "final_pred.to_csv(\"predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
